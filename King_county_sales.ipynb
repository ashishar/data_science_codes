{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "King_county_sales.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUMoWCNm0Pn7gfgbBo9/P/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishar/data_science_codes/blob/main/King_county_sales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Visualation code credit:* https://www.kaggle.com/code/sauravvsrinku/starter-house-sales-in-king-county-8ceb15de-5 and https://www.kaggle.com/code/ronikdedhia/king-county-house-sales "
      ],
      "metadata": {
        "id": "AG--GMj_azHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import kaggle dataset\n",
        "! pip install -q kaggle\n",
        "from google.colab import files\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download harlfoxem/housesalesprediction\n",
        "\n"
      ],
      "metadata": {
        "id": "Rv1baSxM0S84",
        "outputId": "47b88a6b-20fa-4eda-820d-417fea35d7c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "housesalesprediction.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip housesalesprediction.zip\n",
        "!ls"
      ],
      "metadata": {
        "id": "-2TCG-IZCLIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094bcf47-ef54-4b9b-e369-e19c4da6041e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  housesalesprediction.zip\n",
            "replace kc_house_data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "bvUx7fouIpDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
        "# kc_house_data.csv has 21613 rows in reality, but we are only loading/previewing the first 1000 rows\n",
        "data_houseing = pd.read_csv('kc_house_data.csv', delimiter=',', nrows = nRowsRead)\n",
        "data_houseing.dataframeName = 'kc_house_data.csv'\n",
        "nRow, nCol = data_houseing.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "metadata": {
        "id": "LQEisdT9I2fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_houseing.head()"
      ],
      "metadata": {
        "id": "it4gIolgI-5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_houseing.describe().T"
      ],
      "metadata": {
        "id": "UAIvbW02Zo37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution graphs (histogram/bar graph) of column data\n",
        "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
        "    nunique = df.nunique()\n",
        "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
        "    nRow, nCol = df.shape\n",
        "    columnNames = list(df)\n",
        "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
        "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
        "    for i in range(min(nCol, nGraphShown)):\n",
        "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
        "        columnDf = df.iloc[:, i]\n",
        "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
        "            valueCounts = columnDf.value_counts()\n",
        "            valueCounts.plot.bar()\n",
        "        else:\n",
        "            columnDf.hist()\n",
        "        plt.ylabel('counts')\n",
        "        plt.xticks(rotation = 90)\n",
        "        plt.title(f'{columnNames[i]} (column {i})')\n",
        "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
        "    plt.show()\n",
        "  \n",
        "plotPerColumnDistribution(data_houseing, 10, 5)"
      ],
      "metadata": {
        "id": "4-7iHUGJJMSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation matrix\n",
        "def plotCorrelationMatrix(df, graphWidth):\n",
        "    filename = df.dataframeName\n",
        "    df = df.dropna('columns') # drop columns with NaN\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    if df.shape[1] < 2:\n",
        "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
        "        return\n",
        "    corr = df.corr()\n",
        "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
        "    corrMat = plt.matshow(corr, fignum = 1)\n",
        "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.colorbar(corrMat)\n",
        "    plt.title(f'Correlation Matrix for {filename}', fontsize=15)\n",
        "    plt.show()\n",
        "\n",
        "plotCorrelationMatrix(data_houseing, 8)"
      ],
      "metadata": {
        "id": "F7jIvJEjY0sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter plots\n",
        "def plotScatterMatrix(df, plotSize, textSize):\n",
        "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
        "    # Remove rows and columns that would lead to df being singular\n",
        "    df = df.dropna('columns')\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    columnNames = list(df)\n",
        "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
        "        columnNames = columnNames[:10]\n",
        "    df = df[columnNames]\n",
        "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
        "    corrs = df.corr().values\n",
        "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
        "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
        "    plt.suptitle('Scatter and Density Plot')\n",
        "    plt.show()\n",
        "plotScatterMatrix(data_houseing, 20, 10)"
      ],
      "metadata": {
        "id": "2q_z7-tVY_Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(x='price', data=data_houseing);"
      ],
      "metadata": {
        "id": "vXlco4L1ZRAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='bedrooms', data=data_houseing);"
      ],
      "metadata": {
        "id": "TuivUPVGaFdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='price',y='sqft_living',data=data_houseing);"
      ],
      "metadata": {
        "id": "VJH-YyZIaU3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map correlation with the cost of houses\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.scatterplot(x='long',y='lat',data=data_houseing,hue='price');"
      ],
      "metadata": {
        "id": "lNLrlSr5abWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['price','bedrooms','bathrooms','sqft_living','sqft_lot','floors','yr_built','grade']\n",
        "sns.pairplot(data_houseing[features], size = 2.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H9CbnrwTakYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data_houseing.iloc[:,3:]\n",
        "y = data_houseing.iloc[:,2:3]"
      ],
      "metadata": {
        "id": "LYiUnGLpdaOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = data_houseing.loc[:, features]\n",
        "# y = data_houseing.loc[:, ['price']]"
      ],
      "metadata": {
        "id": "bNJpN5jAdcIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = .67)"
      ],
      "metadata": {
        "id": "eHQvNznFc4jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "regr = linear_model.LinearRegression()\n",
        "regr.fit(X_train,y_train)\n",
        "y_pred = regr.predict(X_test)\n",
        "#y_pred"
      ],
      "metadata": {
        "id": "Uycp8cwBdC6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "print('Variance score: %.2f' % regr.score(X_test, y_test))\n",
        "print(\"R^2 Score : %.2f\" % r2_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "JcIyEEC2et_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Polynomial regression could give better results**"
      ],
      "metadata": {
        "id": "TOWAMwT1e1wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=3)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.fit_transform(X_test)\n",
        "#X_train_poly"
      ],
      "metadata": {
        "id": "8DlptD16e9v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regr1 = linear_model.LinearRegression()\n",
        "regr1.fit(X_train_poly,y_train)\n",
        "y_pred_poly=regr1.predict(X_test_poly)\n",
        "#y_pred_poly"
      ],
      "metadata": {
        "id": "JiAcjlCUfJSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Variance score: %.2f' % regr1.score(X_test_poly, y_test))\n",
        "print(\"R^2 Score : %.2f\" % r2_score(y_test,y_pred_poly))"
      ],
      "metadata": {
        "id": "4QQUTlDzfT4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,5):\n",
        "    poly = PolynomialFeatures(degree=i)\n",
        "    x_train_poly = poly.fit_transform(X_train)\n",
        "    x_test_poly = poly.fit_transform(X_test)\n",
        "    regr1 = linear_model.LinearRegression()\n",
        "    regr1.fit(X_train_poly,y_train)\n",
        "    y_pred_poly=regr1.predict(X_test_poly)\n",
        "    print(f\"for degree = {i}\")\n",
        "    print('Variance score: %.2f' % regr1.score(X_test_poly, y_test))\n",
        "    print(\"R^2 Score : %.2f\" % r2_score(y_test,y_pred_poly))"
      ],
      "metadata": {
        "id": "Vp4fwbzFfthv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}